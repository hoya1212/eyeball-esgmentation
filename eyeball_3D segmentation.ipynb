{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0041f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision import transforms, utils\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "\n",
    "import torchio as tio\n",
    "from torchio import IntensityTransform\n",
    "from torchio.transforms.augmentation import RandomTransform\n",
    "from torchio.data import Subject\n",
    "\n",
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomAffine,\n",
    "    RandomElasticDeformation, \n",
    "    RandomNoise,\n",
    "    RandomMotion,\n",
    "    RandomBiasField,\n",
    "    RescaleIntensity,\n",
    "    Resample,\n",
    "    ToCanonical,\n",
    "    ZNormalization,\n",
    "    CropOrPad,\n",
    "    HistogramStandardization,\n",
    "    OneOf,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "\n",
    "def pad_nifti(v,m,d=32):\n",
    "    #vw = np.shape(v)[0]\n",
    "    #vh = np.shape(v)[1]\n",
    "    \n",
    "    vd = np.shape(v)[2]\n",
    "    \n",
    "    if vd > 32:\n",
    "        return v,m\n",
    "\n",
    "    p2 = d - vd\n",
    "    if p2 % 2 == 0:\n",
    "        p2 = p2/2\n",
    "        p2 = int(p2) # 소수점 버림\n",
    "        nv = np.pad(v,((0,0),(0,0),(p2,p2)),'constant',constant_values=0)\n",
    "        nm = np.pad(m,((0,0),(0,0),(p2,p2)),'constant',constant_values=0)\n",
    "        \n",
    "    else:\n",
    "        p2 = p2/2\n",
    "        p2 = int(p2) # 소수점 버림\n",
    "        nv = np.pad(v,((0,0),(0,0),(p2,p2+1)),'constant',constant_values=0)\n",
    "        nm = np.pad(m,((0,0),(0,0),(p2,p2+1)),'constant',constant_values=0)\n",
    "    \n",
    "\n",
    "\n",
    "    return nv,nm\n",
    "\n",
    "# z score normalization\n",
    "def z_score(data, lth = 0.02, uth = 0.98):\n",
    "\n",
    "    temp = np.sort(data[data>0])\n",
    "    lth_num = np.int(temp.shape[0]*0.02)\n",
    "    uth_num = np.int(temp.shape[0]*0.98)\n",
    "    data_mean = np.mean(temp[lth_num:uth_num])\n",
    "    data_std = np.std(temp[lth_num:uth_num])\n",
    "    data = (data - data_mean)/data_std\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "        \n",
    "train_transform = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    tio.OneOf({\n",
    "        tio.Lambda(lambda x:x, types_to_apply=None):0.34,\n",
    "        tio.RandomAffine(scales=(0.95,1.25), degrees=0, image_interpolation='linear',isotropic=True, center='image'):0.33,\n",
    "        tio.RandomElasticDeformation(num_control_points=5, image_interpolation='linear'):0.33,      \n",
    "              \n",
    "              \n",
    "    }),\n",
    "    tio.OneOf({\n",
    "        tio.Lambda(lambda x:x, types_to_apply=None):0.34,\n",
    "        tio.RandomBiasField():0.33, \n",
    "        tio.RandomGamma(log_gamma=(-0.05,0.05)):0.33,\n",
    "              \n",
    "    }),\n",
    "\n",
    "])\n",
    "\n",
    "valtest_transform = tio.Compose([\n",
    "    tio.ToCanonical()\n",
    "    \n",
    "])\n",
    "\n",
    "# custom dataloader\n",
    "class BrainSegmentationDataset(Dataset):     \n",
    "    # split dataset and read the specified partition\n",
    "    def __init__(self, images_dir, transform=None, mode=\"train\", K=0, num_folds=10, random_state=11, val_split=0.1):\n",
    "        assert mode in [\"train\", \"validation\",\"test\"]\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        volumes = []\n",
    "        masks = []\n",
    "        files = []\n",
    "        \n",
    "        v_list = sorted(glob.glob(images_dir))\n",
    "        m_list = sorted(glob.glob(images_dir))      \n",
    "        \n",
    "        # subject weights (by the number of foreground voxels)\n",
    "        subj_weights = np.zeros((len(m_list),))\n",
    "        cnt = 0\n",
    "        for i in range(len(m_list)):\n",
    "                tmpmask = nib.load(m_list[i]).get_fdata()\n",
    "                tmpidx = np.where(tmpmask > 0.5)[-1]\n",
    "                subj_weights[cnt] = len(tmpidx)\n",
    "                cnt = cnt + 1\n",
    "        \n",
    "        # split the subjects by median value\n",
    "        subj_weights = np.where(subj_weights > np.median(subj_weights),1,0)\n",
    "        \n",
    "        cnt_idx = np.arange(len(v_list)) # 0, 1, 2, ..., num_subj-1\n",
    "        kf = StratifiedKFold(n_splits=num_folds,shuffle=True,random_state=random_state)\n",
    "        train_indices,validation_indices,test_indices = {},{},{}\n",
    "        cnt = 0\n",
    "        for train_validation_idx, test_idx in kf.split(cnt_idx,subj_weights): \n",
    "            splits = train_test_split(train_validation_idx, \n",
    "                                      shuffle=True,\n",
    "                                      random_state=random_state,\n",
    "                                      test_size=val_split,\n",
    "                                     stratify=subj_weights[train_validation_idx])\n",
    "            train_indices[str(cnt)], validation_indices[str(cnt)] = splits[0], splits[1]\n",
    "            test_indices[str(cnt)] = test_idx\n",
    "            cnt += 1\n",
    "            \n",
    "        if mode == 'train':\n",
    "            sel = train_indices[str(K)]\n",
    "        elif mode == 'validation':\n",
    "            sel = validation_indices[str(K)]\n",
    "        elif mode == 'test':\n",
    "            sel = test_indices[str(K)]\n",
    "            \n",
    "        # read images \n",
    "        print(\"reading {} images...\".format(mode))\n",
    "        print(\"The length of {} set is: {}\".format(mode, len(sel)))\n",
    "\n",
    "        for i in range(len(v_list)):\n",
    "            if np.any(sel == i):\n",
    "                v = nib.load(v_list[i]).get_fdata()\n",
    "                m = nib.load(m_list[i]).get_fdata()\n",
    "                v,m = pad_nifti(v,m)\n",
    "                v = z_score(v)\n",
    "                print(\"{} || {}\".format(v_list[i],m_list[i]))\n",
    "\n",
    "                volumes.append(v)\n",
    "                masks.append(m)\n",
    "                \n",
    "        print(\"Number of volumes {} set is: {}\".format(mode, len(volumes)))\n",
    "        self.volumes = volumes\n",
    "        self.masks = masks\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.volumes)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print('idx:'+idx)\n",
    "        image = self.volumes[idx]\n",
    "        mask = self.masks[idx]   \n",
    "\n",
    "        \n",
    "        image = torch.from_numpy(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        image = torch.unsqueeze(image,0)\n",
    "        mask = torch.unsqueeze(mask,0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        subject_dict = {\n",
    "            'image': tio.ScalarImage(tensor=image),\n",
    "            'mask': tio.LabelMap(tensor=mask),\n",
    "        }\n",
    "\n",
    "        subject = tio.Subject(subject_dict)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            subject = self.transform(subject)\n",
    "        \n",
    "        image = subject['image'].tensor\n",
    "        mask = subject['mask'].tensor\n",
    "\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffa066",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "GPU_NUM = 4\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) \n",
    "print ('Current cuda device Number =', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('Current cuda device Name =', torch.cuda.get_device_name(GPU_NUM))\n",
    "    print('Current cuda device Memory =', (torch.cuda.get_device_properties(GPU_NUM).total_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(inputs, label, predicted):\n",
    "    #_, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "    inputs = (inputs.cpu()).numpy()  \n",
    "    label = (label.cpu()).numpy()\n",
    "    predicted = (predicted.cpu()).numpy()\n",
    "\n",
    "    inputs = inputs.astype(np.float)[0]    \n",
    "    label = label.astype(np.uint8)[0]\n",
    "    predicted = predicted.astype(np.uint8)[0]\n",
    "\n",
    "    inputs = np.transpose(inputs,(1,2,0))\n",
    "    label = np.transpose(label,(1,2,0))\n",
    "    predicted = np.transpose(predicted,(1,2,0))\n",
    "    #print(inputs.shape)\n",
    "    #print(label.shape)\n",
    "    #print(predicted.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax1.imshow(inputs, cmap=\"gray\")\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax2.imshow(label, cmap='gray', vmin=0, vmax=1)\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.set_yticklabels([])\n",
    "    ax3 = fig.add_subplot(1,3,3)\n",
    "    ax3.imshow(predicted, cmap='gray',vmin=0, vmax=1)\n",
    "    ax3.set_xticklabels([])\n",
    "    ax3.set_yticklabels([])      \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def flatten(tensor):\n",
    "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
    "    The shapes are transformed as follows:\n",
    "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
    "    \"\"\"\n",
    "    # number of channels\n",
    "    C = tensor.size(1)\n",
    "    # new axis order\n",
    "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
    "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
    "    transposed = tensor.permute(axis_order)\n",
    "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
    "    return transposed.contiguous().view(C, -1)\n",
    "\n",
    "\n",
    "def compute_per_channel_dice(input, target, epsilon=1e-6, weight=None):\n",
    "    \"\"\"\n",
    "    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.\n",
    "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
    "    Args:\n",
    "         input (torch.Tensor): NxCxSpatial input tensor\n",
    "         target (torch.Tensor): NxCxSpatial target tensor\n",
    "         epsilon (float): prevents division by zero\n",
    "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
    "    \"\"\"\n",
    "\n",
    "    # input and target shapes must match\n",
    "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "    \n",
    "    input = flatten(input)\n",
    "    target = flatten(target)\n",
    "    target = target.float()\n",
    "\n",
    "    # compute per channel Dice Coefficient\n",
    "    intersect = (input * target).sum(-1)\n",
    "    if weight is not None:\n",
    "        intersect = weight * intersect\n",
    "\n",
    "    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)\n",
    "    denominator = (input * input).sum(-1) + (target * target).sum(-1)\n",
    "    return 2 * (intersect / denominator.clamp(min=epsilon))\n",
    "\n",
    "     \n",
    "class DiceCoefficient:\n",
    "    \"\"\"Computes Dice Coefficient.\n",
    "    Generalized to multiple channels by computing per-channel Dice Score\n",
    "    (as described in https://arxiv.org/pdf/1707.03237.pdf) and theTn simply taking the average.\n",
    "    Input is expected to be probabilities instead of logits.\n",
    "    This metric is mostly useful when channels contain the same semantic class (e.g. affinities computed with different offsets).\n",
    "    DO NOT USE this metric when training with DiceLoss, otherwise the results will be biased towards the loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-6, **kwargs):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, input, target):\n",
    "        #target = torch.unsqueeze(target,1)\n",
    "        # Average across channels in order to get the final score\n",
    "        return torch.mean(compute_per_channel_dice(input, target, epsilon=self.epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import BasicUNet\n",
    "\n",
    "unet = BasicUNet(spatial_dims=3, out_channels=3,dropout=0.3, features=(32, 32, 64, 128, 256, 32))\n",
    "\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(images, K=0, num_folds=10,random_state=10,val_split=0.1):\n",
    "    train = BrainSegmentationDataset(\n",
    "        images_dir = images,\n",
    "        mode=\"train\",\n",
    "        transform=train_transform,\n",
    "        K=K,num_folds=num_folds,random_state=random_state,val_split=val_split,\n",
    "    )\n",
    "    valid = BrainSegmentationDataset(\n",
    "        images_dir = images,\n",
    "        mode=\"validation\",\n",
    "        transform=valtest_transform,\n",
    "        K=K,num_folds=num_folds,random_state=random_state,val_split=val_split,\n",
    "    )\n",
    "    test = BrainSegmentationDataset(\n",
    "        images_dir = images,\n",
    "        mode=\"test\",\n",
    "        transform=valtest_transform,\n",
    "        K=K,num_folds=num_folds,random_state=random_state,val_split=val_split,\n",
    "    )\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "def data_loaders(image_path, batch_size, K=0):\n",
    "    dataset_train, dataset_valid, dataset_test = datasets(image_path, K=K)\n",
    "\n",
    "    \n",
    "    loader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    " \n",
    "    )\n",
    "    loader_valid = DataLoader(\n",
    "        dataset_valid,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        drop_last=True\n",
    "\n",
    "    )\n",
    "    loader_test = DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        drop_last=True\n",
    "\n",
    "    )\n",
    "\n",
    "    return loader_train, loader_valid, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "LR = 1e-4\n",
    "weights = './'\n",
    "loss1 = DiceLoss(to_onehot_y = True)\n",
    "optimizer = optim.AdamW(unet.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1daca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "loader_train, loader_valid, loader_test = data_loaders('./', batch_size=1, K=0)\n",
    "loaders = {\"train\": loader_train, \"valid\": loader_valid, \"test\" : loader_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_validation_dsc = 0.0\n",
    "\n",
    "loss_train=[]\n",
    "loss_valid=[]\n",
    "\n",
    "allloss_train = []\n",
    "alldsc_train = []\n",
    "allloss_val = []\n",
    "alldsc_val = []\n",
    "\n",
    "dsc = DiceCoefficient()\n",
    "\n",
    "# actual processing...\n",
    "step = 0\n",
    "print(\"1 Fold\")\n",
    "#print(num_folds)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for phase in [\"train\", \"valid\"]:\n",
    "        if phase == \"train\":\n",
    "            unet.train()\n",
    "        else:\n",
    "            unet.eval()\n",
    "            \n",
    "        train_dsc_list = []\n",
    "        validation_dsc_list = []\n",
    "        \n",
    "        \n",
    "        for i, data in enumerate(loaders[phase]):\n",
    "            if phase == \"train\": step += 1\n",
    "            x, y_true = data \n",
    "            x, y_true = x.to(device).float(),y_true.to(device).float()\n",
    "            #print(x.shape)\n",
    "            #for i in range(176):\n",
    "                #plot_img(x[:,:,:,:,i], y_true[:,:,:,:,i], y_true[:,:,:,:,i])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #print(y_true.shape)\n",
    "            \n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): \n",
    "                \n",
    "                y_pred = unet(x) # forwarding\n",
    "                y_pred = F.softmax(y_pred,dim=1)\n",
    "                \n",
    "                loss_1 = loss1(y_pred, y_true) \n",
    "                \n",
    "                loss = loss_1 \n",
    "                \n",
    "                \n",
    "                if phase == \"train\":\n",
    "                    \n",
    "                    loss_train.append(loss.item())\n",
    "                    \n",
    "                    \n",
    "                    y_pred = torch.argmax(y_pred,dim=1,keepdim=True)\n",
    "                    f1 = dsc(y_pred, y_true)\n",
    "                    train_dsc_list.append(f1.item())\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step() \n",
    "                  \n",
    "                    \n",
    "                if phase == \"valid\":\n",
    "                    loss_valid.append(loss.item()) # gathering the loss\n",
    "                    y_pred = torch.argmax(y_pred,dim=1,keepdim=True)\n",
    "                    f1 = dsc(y_pred, y_true)\n",
    "                    validation_dsc_list.append(f1.item())\n",
    "                    \n",
    "        if phase == \"train\": # reporting\n",
    "            print(\"epoch {:04d}     | {}: {}\".format(epoch + 1, \"Train loss\", np.mean(loss_train)))\n",
    "            print(\"               | {}: {}\".format(\"Train Dice\", np.mean(train_dsc_list)))\n",
    "            allloss_train.append(np.mean(loss_train))\n",
    "            alldsc_train.append(np.mean(train_dsc_list))\n",
    "            loss_train = []\n",
    "            \n",
    "        if phase == \"valid\": #reporting\n",
    "            print(\"               | {}: {}\".format(\"Validation loss\", np.mean(loss_valid)))\n",
    "            print(\"               | {}: {}\".format(\"Validation Dice\", np.mean(validation_dsc_list)))\n",
    "            \n",
    "                       \n",
    "                # save best model\n",
    "            if np.mean(validation_dsc_list) > best_validation_dsc:\n",
    "                best_validation_dsc = np.mean(validation_dsc_list)\n",
    "                torch.save(unet.state_dict(), os.path.join(weights, 'basic_UNet_1fold.pth'))\n",
    "                print(\"\\n save dice : {:4f}\\n\".format(best_validation_dsc))  \n",
    "                  \n",
    "            \n",
    "            alldsc_val.append(np.mean(validation_dsc_list))\n",
    "            allloss_val.append(np.mean(loss_valid))\n",
    "            loss_valid = []\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "                    \n",
    "            \n",
    "        \n",
    "print(\"\\nBest validation mean DSC: {:4f}\\n\".format(best_validation_dsc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyeball",
   "language": "python",
   "name": "eyeball"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
